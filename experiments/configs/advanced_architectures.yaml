experiments:
  - name: "GraphAttention_4Heads"
    model:
      name: "AttentionCGCNN"
      params:
        node_fea_dim: 64
        num_layers: 3
        invariant: true
        cutoff: 12.0
        max_neighbors: 30
        heads: 4
        dropout: 0.1

  - name: "GraphAttention_8Heads"
    model:
      name: "AttentionCGCNN"
      params:
        node_fea_dim: 64
        num_layers: 3
        invariant: true
        cutoff: 12.0
        max_neighbors: 30
        heads: 8
        dropout: 0.1

  - name: "EnhancedCGCNN_Attention"
    model:
      name: "EnhancedCGCNN"
      params:
        node_fea_dim: 64
        num_layers: 3
        invariant: true
        cutoff: 12.0
        max_neighbors: 30
        use_attention: true
        dropout: 0.1

training:
  batch_size: 32
  learning_rate: 0.001
  num_epochs: 100

optimizer: "AdamW"
